{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Downloading French Legal Codes\n",
				"\n",
				"This notebook demonstrates how to download various French legal codes from Légifrance and save them into HTML files. The codes include the Civil Code, Penal Code, Commercial Code, and many others.\n",
				"\n",
				"[Download a law](https://www.legifrance.gouv.fr/search/all?tab_selection=all&searchField=ALL&query=&page=1&init=true)\n",
				"\n",
				"## Legal Codes Included\n",
				"1. Code de l'action sociale et des familles\n",
				"2. Code de l'artisanat\n",
				"3. Code des assurances\n",
				"4. Code de l'aviation civile\n",
				"5. Code du cinéma et de l'image animée\n",
				"6. Code civil V\n",
				"7. Code de la commande publiqu\n",
				"8. Code de commerce V\n",
				"9. Code des communes V\n",
				"10. Code de la consommation\n",
				"11. Code de la construction et de l'habitation\n",
				"12. Code de la défense\n",
				"13. Code de l'éducation\n",
				"14. Code électoral\n",
				"15. Code de l'énergie\n",
				"16. Code de l'environnement\n",
				"17. Code de l'entrée et du séjour des étrangers et du droit d'asile\n",
				"18. Code général des collectivités territoriales\n",
				"19. Code général des impôts\n",
				"20. Code général de la fonction publique\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"import yake\n",
				"\n",
				"def extract_keywords_from_article(text, num_keywords):\n",
				"    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=3, dedupLim=0.9, top=num_keywords)\n",
				"    keywords = kw_extractor.extract_keywords(text)\n",
				"    return [kw[0] for kw in keywords]\n",
				"\n",
				"def generate_embeddings(text):\n",
				"  return [0.0] * 768"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"ename": "ValueError",
					"evalue": "\u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/migration for more information or join our discord at https://discord.gg/8g5FESbj for help!\u001b[0m",
					"output_type": "error",
					"traceback": [
						"\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
						"Cell \u001b[0;32mIn[7], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     neo4j_db\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
						"Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m---> 38\u001b[0m     chroma_db \u001b[38;5;241m=\u001b[39m \u001b[43mChromaDBInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCHROMA_DB_PATH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     neo4j_db \u001b[38;5;241m=\u001b[39m Neo4jInterface(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEO4J_URI\u001b[39m\u001b[38;5;124m'\u001b[39m), os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEO4J_USER\u001b[39m\u001b[38;5;124m'\u001b[39m), os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEO4J_PASSWORD\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Process each PDF in the input directory\u001b[39;00m\n",
						"File \u001b[0;32m~/Desktop/SexualContent/ActualFuckingDevLab/AIProjects/Demetrius/Demetrius-law-chat-bot-ai/database_interfaces.py:7\u001b[0m, in \u001b[0;36mChromaDBInterface.__init__\u001b[0;34m(self, db_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, db_path):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchroma_db_impl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mduckdb+parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marticles_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mget_or_create_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
						"File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/__init__.py:274\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(settings, tenant, database)\u001b[0m\n\u001b[1;32m    271\u001b[0m tenant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[1;32m    272\u001b[0m database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
						"File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/client.py:139\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, tenant, database, settings)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    135\u001b[0m     tenant: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_TENANT,\n\u001b[1;32m    136\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    137\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[1;32m    138\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtenant \u001b[38;5;241m=\u001b[39m tenant\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase \u001b[38;5;241m=\u001b[39m database\n",
						"File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/client.py:43\u001b[0m, in \u001b[0;36mSharedSystemClient.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     40\u001b[0m     settings: Settings \u001b[38;5;241m=\u001b[39m Settings(),\n\u001b[1;32m     41\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier \u001b[38;5;241m=\u001b[39m SharedSystemClient\u001b[38;5;241m.\u001b[39m_get_identifier_from_settings(settings)\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mSharedSystemClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_system_if_not_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
						"File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/client.py:50\u001b[0m, in \u001b[0;36mSharedSystemClient._create_system_if_not_exists\u001b[0;34m(cls, identifier, settings)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_system_if_not_exists\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mcls\u001b[39m, identifier: \u001b[38;5;28mstr\u001b[39m, settings: Settings\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m System:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m identifier \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_identifer_to_system:\n\u001b[0;32m---> 50\u001b[0m         new_system \u001b[38;5;241m=\u001b[39m \u001b[43mSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_identifer_to_system[identifier] \u001b[38;5;241m=\u001b[39m new_system\n\u001b[1;32m     53\u001b[0m         new_system\u001b[38;5;241m.\u001b[39minstance(ProductTelemetryClient)\n",
						"File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/config.py:336\u001b[0m, in \u001b[0;36mSystem.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Validate settings don't contain any legacy config values\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _legacy_config_keys:\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    340\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchroma_segment_cache_policy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchroma_segment_cache_policy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLRU\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m ):\n",
						"File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/config.py:273\u001b[0m, in \u001b[0;36mSettings.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Error on legacy config values\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m _legacy_config_values:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
						"\u001b[0;31mValueError\u001b[0m: \u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/migration for more information or join our discord at https://discord.gg/8g5FESbj for help!\u001b[0m"
					]
				}
			],
			"source": [
				"# main.py\n",
				"\n",
				"import os\n",
				"import logging\n",
				"from law_pdf_parser import extract_articles_from_pdf\n",
				"from database_interfaces import ChromaDBInterface\n",
				"from database_interfaces import Neo4jInterface\n",
				"from tqdm import tqdm\n",
				"from dotenv import load_dotenv \n",
				"load_dotenv() \n",
				"\n",
				"# Set up logging\n",
				"logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
				"logger = logging.getLogger(__name__)\n",
				"\n",
				"def process_article(article, document_name, chroma_db, neo4j_db):\n",
				"    \"\"\"Process a single article.\"\"\"\n",
				"    try:\n",
				"        # Generate embeddings\n",
				"        article_embedding = generate_embeddings(article['content'])\n",
				"        \n",
				"        # Extract keywords\n",
				"        num_keywords = max(int(len(article['content']) * 0.05), 1)\n",
				"        keywords = extract_keywords_from_article(article['content'], num_keywords)\n",
				"        \n",
				"        # Store in ChromaDB\n",
				"        chroma_db.store_article(document_name, article['number'], article['content'], article_embedding)\n",
				"        chroma_db.store_keywords(document_name, article['number'], keywords)\n",
				"        \n",
				"        # Store in Neo4j\n",
				"        neo4j_db.store_article(document_name, article['number'], article['content'])\n",
				"        \n",
				"        logger.info(f\"Processed Article {article['number']} from {document_name}\")\n",
				"    except Exception as e:\n",
				"        logger.error(f\"Error processing Article {article['number']} from {document_name}: {str(e)}\")\n",
				"\n",
				"def main():\n",
				"    chroma_db = ChromaDBInterface(os.environ.get('CHROMA_DB_PATH'))\n",
				"    neo4j_db = Neo4jInterface(os.environ.get('NEO4J_URI'), os.environ.get('NEO4J_USER'), os.environ.get('NEO4J_PASSWORD'))\n",
				"    \n",
				"    # Process each PDF in the input directory\n",
				"    input_dir = \"database/laws/\"\n",
				"    for filename in tqdm(os.listdir(input_dir), desc=\"Processing files\"):\n",
				"        if filename.endswith('.pdf'):\n",
				"            pdf_path = os.path.join(input_dir, filename)\n",
				"            document_name = os.path.splitext(filename)[0]\n",
				"            \n",
				"            logger.info(f\"Processing {filename}\")\n",
				"            \n",
				"            try:\n",
				"                articles = extract_articles_from_pdf(pdf_path)\n",
				"                for article in articles:\n",
				"                    process_article(article, document_name, chroma_db, neo4j_db)\n",
				"                \n",
				"                logger.info(f\"Completed processing {filename}\")\n",
				"            except Exception as e:\n",
				"                logger.error(f\"Error processing {filename}: {str(e)}\")\n",
				"    \n",
				"    # Close database connections\n",
				"    chroma_db.close()\n",
				"    neo4j_db.close()\n",
				"\n",
				"if __name__ == \"__main__\":\n",
				"    main()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Future prompts :\n",
				"\n",
				"---\n",
				"```plain_text\n",
				"For context here are all the previous user's query\n",
				"[conversation, only user inputs]\n",
				"\n",
				"Following, is their last query\n",
				"[last user input]\n",
				"\n",
				"Generate a more refined query of the last user's query based on all the previous queries. Your refined query will be use to prompt a retrieval chain so make it clear and self contained.\n",
				"Make sure the query is self contained and contains all the information required to properly query a law database.\n",
				"You will achieve this after a step by step detailed break down of logic.\n",
				"At the end of the break down you will finally give your final answer and final query using the following format, capital words are my place holder :\n",
				"\"<query>\n",
				"FINAL_ENHANCED_QUERY\n",
				"</query>\"\n",
				"Please respect the given format.\n",
				"```\n",
				"---\n",
				"\n",
				"-> Put the result {query} of this into the following :\n",
				"\n",
				"---\n",
				"\n",
				"# Future code :\n",
				"\n",
				"```python\n",
				"pre_processed_query = query_pre_processing(query)\n",
				"enhanced_query = enhance_query_keywords(pre_processed_query)\n",
				"```\n",
				"---\n",
				"```python\n",
				"def enhance_query_keywords(query):\n",
				"    logger.info(f\"Enhancing query with keywords: {query}\")\n",
				"    try:\n",
				"        # Extract keywords from the query\n",
				"        query_keywords = extract_keywords(query, num_of_keywords=max(0.3*len(query.split(\" \")), 8))\n",
				"        # Generate embeddings for each query keyword\n",
				"        embeddings = {keyword: get_embeddings_openai(keyword) for keyword in query_keywords}\n",
				"        enhanced_keywords = {}\n",
				"        for keyword, embedding in embeddings.items():\n",
				"            # Find similar keywords in the collection using the embedding\n",
				"            results = collection_embeddings.query(query_embeddings=[embedding], n_results=5)\n",
				"            similar_keywords = results['documents'][0]  # Assume results are structured with documents containing the keywords\n",
				"            # Add similar keywords to the set\n",
				"            enhanced_keywords[keyword] = set(similar_keywords)\n",
				"        # Replace each keyword in the original query with the augmented keywords\n",
				"        enhanced_query = []\n",
				"        for word in query.split():\n",
				"            if word in enhanced_keywords:\n",
				"                # Replace the word with the original and similar keywords\n",
				"                augmented_keywords = ' '.join(enhanced_keywords[word])\n",
				"                enhanced_query.append(f\"{word} {augmented_keywords}\")\n",
				"            else:\n",
				"                enhanced_query.append(word)\n",
				"        enhanced_query_str = ' '.join(enhanced_query)\n",
				"        logger.info(f\"Enhanced query: {enhanced_query_str}\")\n",
				"        return enhanced_query_str\n",
				"    except Exception as e:\n",
				"        logger.error(f\"Error enhancing query keywords: {e}\")\n",
				"        return query\n",
				"```\n",
				"---\n",
				"```python\n",
				"nltk.download('stopwords')\n",
				"nltk.download('punkt')\n",
				"nltk.download('wordnet')\n",
				"def query_pre_processing(query):\n",
				"    logger.info(f\"{WHITE}Pre-processing query: {BLUE}{ITALIC}{query}{RESET}\")\n",
				"    try:\n",
				"        # Tokenization\n",
				"        tokens = word_tokenize(query.lower())\n",
				"        # Stopword Removal\n",
				"        stop_words = set(stopwords.words('english'))\n",
				"        tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
				"        # Stemming\n",
				"        stemmer = PorterStemmer()\n",
				"        tokens = [stemmer.stem(word) for word in tokens]\n",
				"        # Lemmatization\n",
				"        lemmatizer = WordNetLemmatizer()\n",
				"        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
				"        processed_query = ' '.join(tokens)\n",
				"        logger.info(f\"{WHITE}Processed query: {BLUE}{ITALIC}{processed_query}{RESET}\")\n",
				"        return processed_query\n",
				"    except Exception as e:\n",
				"        logger.error(f\"Error in query pre-processing: {e}\")\n",
				"        return query\n",
				"```"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.12"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
